---
layout: post
title: "中文分词入门之字标注法4"
date: '2014-01-01T12:39:00.000+08:00'
author: Wenh Q
tags:
- tech
modified_time: '2014-01-01T12:39:01.934+08:00'
blogger_id: tag:blogger.com,1999:blog-4961947611491238191.post-7644748828747504605
blogger_orig_url: http://binaryware.blogspot.com/2014/01/4.html
---

<div dir="ltr"><div class="gmail_quote"><br /><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%954" style="color: black; font-size: 24px; font-weight: bold; text-decoration: none;" target="_blank">中文分词入门之字标注法4</a></div><br /><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #f2f2f2; color: #303030; padding: 20px 40px 20px 40px; text-align: left;"><div style="margin-top: 15px;">通过 <a href="http://www.52nlp.cn/" style="font-size: 13px;" target="_blank">我爱自然语言处理</a>              </div><div dir="ltr" style="font-size: 14px; line-height: 20px; margin-top: 15px;"><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%953" target="_blank">上一节</a>主要介绍的是利用最大熵工具包来做字标注<a href="http://www.52nlp.cn/category/word-segmentation" target="_blank">中文分词</a>，这一节我们直奔主题，借用条件随机场工具"<a href="http://crfpp.googlecode.com/svn/trunk/doc/index.html" target="_blank">CRF++: Yet Another CRF toolkit</a>"来完成字标注中文分词的全过程。<br />关于条件随机场（CRF）的背景知识，推荐参考阅读一些经典的文献：《<a href="http://www.52nlp.cn/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E6%8C%87%E5%8D%97" target="_blank">条件随机场文献阅读指南</a>》，另外再额外推荐一个tutorial:《<a href="http://www.scai.fraunhofer.de/fileadmin/images/bio/data_mining/paper/crf_klinger_tomanek.pdf" target="_blank">Classical Probabilistic Models and Conditional Random Fields</a>》, 这份关于CRF的文档分别从概率模型（NB，HMM，ME， CRF)之间的关系以及概率图模型背景来介绍条件随机场，比较清晰：<br /><blockquote>While  a Hidden Markov Model is a sequential extension to the Na ve Bayes  Model, Conditional Random Fields can be understood as a sequential  extension to the Maximum Entropy Model.</blockquote>如果这些还不够过瘾，推荐<a href="http://coursegraph.com/" target="_blank">课程图谱</a>上收录的Coursera创始人之一Daphne Koller的"<a href="http://coursegraph.com/probabilistic-graphical-models-coursera-pgm-stanford-university" target="_blank">概率图模型公开课</a>"，相信拿下这门课之后，对于上述概率模型，会有一种"一览众山小"的感觉。<br /><br />不过我们还是要从安装CRF++工具包说起，在Linux或者Mac OS系统下，下载C++源代码安装包(这里用的是 <a href="https://crfpp.googlecode.com/files/CRF%2B%2B-0.58.tar.gz" target="_blank">CRF++-0.58.tar.gz</a> ）之后，依然是 "configure &amp; make &amp; (sudo) make install"，安装完毕之后，可以cd  python进入到其同样用SWIG生成的Python工具包下，安装python包：python setup.py build &amp;  (sudo) python setup.py install。安装完毕之后，可以在python解释器下测试，是否能成功import  CRFPP，如果ok，则准备工作就绪。<br />上一节我们利用最大熵模型工具包里自带的词性标注工具进行的中文分词，稍微有些曲折，这一节我们依 然利用CRF++ example里的样例进行测试，不过好处是，CRF++  example里有个seg目录，这个seg目录对应的是一个日文分词的样例，正好可以套用到我们的中文分词中来。在安装包目录下，cd  example, cd seg目录后，有4个文件：<br /><blockquote>exec.sh（执行脚本）<br />template（特征模板）<br />test.data（测试集）<br />train.data（训练集)</blockquote>有了这4个文件，我们可以做得事情就比较简单，只要按测试集，训练集的格式准备数据就可以了，特征模板和执行脚本可以套用，不过这里简单解读一下这几个CRF++文件。首先来看训练集：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">毎 k &nbsp; B<br />日 k &nbsp; I<br />新 k &nbsp; I<br />聞 k &nbsp; I<br />社 k &nbsp; I<br />特 k &nbsp; B<br />別 k &nbsp; I<br />顧 k &nbsp; B<br />問 k &nbsp; I &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />４ n &nbsp; B</div></td></tr></tbody></table></div>这里第一列是待分词的日文字，第二列暂且认为其是词性标记，第三列是字标注中的2-tag(B, I)标记，这个很重要，对于我们需要准备的训练集，主要是把这一列的标记做好，不过需要注意的是，其断句是靠空行来完成的。<br />再来看测试集的格式：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">よ h &nbsp; I<br />っ h &nbsp; I<br />て h &nbsp; I<br />私 k &nbsp; B<br />た h &nbsp; B<br />ち h &nbsp; I<br />の h &nbsp; B &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />世 k &nbsp; B<br />代 k &nbsp; I<br />が h &nbsp; B</div></td></tr></tbody></table></div>同 样也有3列，第一列是日文字，第二列第三列与上面是相似的，不过在测试集里第三列主要是占位作用。事实上，CRF++对于训练集和测试集文件格式的要求是 比较灵活的，首先需要多列，但不能不一致，既在一个文件里有的行是两列，有的行是三列；其次第一列代表的是需要标注的"字或词"，最后一列是输出位"标记 tag"，如果有额外的特征，例如词性什么的，可以加到中间列里，所以训练集或者测试集的文件最少要有两列。<br />接下里我们再来详细的分析一下特征模板文件：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11<br />12<br />13<br />14</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;"># Unigram<br />U00:%x[-2,0]<br />U01:%x[-1,0]<br />U02:%x[0,0]<br />U03:%x[1,0]<br />U04:%x[2,0]<br />U05:%x[-2,0]/%x[-1,0]/%x[0,0]<br />U06:%x[-1,0]/%x[0,0]/%x[1,0]<br />U07:%x[0,0]/%x[1,0]/%x[2,0]<br />U08:%x[-1,0]/%x[0,0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />U09:%x[0,0]/%x[1,0]<br /><br /># Bigram<br />B</div></td></tr></tbody></table></div>关于CRF++中特征模板的说明和举例，请大家参考官方文档上的"<a href="http://crfpp.googlecode.com/svn/trunk/doc/index.html#templ" target="_blank">Preparing feature templates</a>" 这一节，而以下部分的说明拿上述日文分词数据举例。在特征模板文件中，每一行(如U00:%x[-2,0]）代表一个特征，而宏"%x[行位置,列位 置]"则代表了相对于当前指向的token的行偏移和列的绝对位置，以上述训练集为例，如果当前扫描到"新 k       I"这一行，<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">毎 k &nbsp; B<br />日 k &nbsp; I<br />新 k &nbsp; I &nbsp; &lt;== 扫描到这一行，代表当前位置<br />聞 k &nbsp; I<br />社 k &nbsp; I<br />特 k &nbsp; B<br />別 k &nbsp; I<br />顧 k &nbsp; B<br />問 k &nbsp; I<br />４ n &nbsp; B</div></td></tr></tbody></table></div>那么依据特征模板文件抽取的特征如下：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11<br />12<br />13<br />14</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;"># Unigram<br />U00:%x[-2,0] ==&gt; 毎<br />U01:%x[-1,0] ==&gt; 日<br />U02:%x[0,0] &nbsp;==&gt; 新<br />U03:%x[1,0] &nbsp;==&gt; 聞<br />U04:%x[2,0] &nbsp;==&gt; 社<br />U05:%x[-2,0]/%x[-1,0]/%x[0,0] ==&gt; 每/日/新<br />U06:%x[-1,0]/%x[0,0]/%x[1,0] &nbsp;==&gt; 日/新/聞<br />U07:%x[0,0]/%x[1,0]/%x[2,0] &nbsp; ==&gt; 新/聞/社<br />U08:%x[-1,0]/%x[0,0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;==&gt; 日/新<br />U09:%x[0,0]/%x[1,0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ==&gt; 新/聞<br /><br /># Bigram<br />B</div></td></tr></tbody></table></div>CRF++里将特征分成两种类型，一种是Unigram的，"U"起头，另外一种是Bigram的，"B"起头。对于Unigram的特征，假如一个特征模板是"U01:%x[-1,0]", CRF++会自动的生成一组特征函数(func1 … funcN) 集合:<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">func1 = if (output = B and feature="U01:日") return 1 else return 0<br />func2 = if (output = I and feature="U01:日") return 1 else return 0<br />...<br />funcXX = if (output = B and feature="U01:問") return 1 &nbsp;else return 0<br />funcXY = if (output = I and feature="U01:問") return 1 &nbsp;else return 0</div></td></tr></tbody></table></div>生成的特征函数的数目 = (L * N)，其中L是输出的类型的个数，这里是B，I这两个tag，N是通过模板扩展出来的所有单个字符串(特征）的个数，这里指的是在扫描所有训练集的过程中找到的日文字（特征）。<br />而 Bigram特征主要是当前的token和前面一个位置token的自动组合生成的bigram特征集合。最后需要注意的是U01和U02这些标志位，与 特征token组合到一起主要是区分"U01:問"和"U02:問"这类特征，虽然抽取的日文"字"特征是一样的，但是在CRF++中这是有区别的特征。<br />最后我们再来看一下执行脚本：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">#!/bin/sh<br />./../crf_learn -f 3 -c 4.0 template train.data model<br />./../crf_test -m model test.data<br /><br />./../crf_learn -a MIRA -f 3 template train.data model<br />./../crf_test -m model test.data<br />rm -f model</div></td></tr></tbody></table></div>执行脚本告诉了我们如何训练一个CRF模型，以及如何利用这个模型来进行测试，执行这个脚本之后，对于输入的测试集，输出结果多了一列：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">よ h &nbsp; I &nbsp; B<br />っ h &nbsp; I &nbsp; I<br />て h &nbsp; I &nbsp; B<br />私 k &nbsp; B &nbsp; B<br />た h &nbsp; B &nbsp; B<br />ち h &nbsp; I &nbsp; I<br />の h &nbsp; B &nbsp; B &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />世 k &nbsp; B &nbsp; B<br />代 k &nbsp; I &nbsp; I<br />が h &nbsp; B &nbsp; B</div></td></tr></tbody></table></div>而这一列才是模型预测的改字的标记tag，也正是我们所需要的结果。到此为止，关于日文分词样例的介绍已经完毕，读者应该可以猜测到接下来我们会如何做中文分词吧？<br />和上一节利用<a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%953" target="_blank">最大熵模型进行中文分词</a>相 似，第一步仍然是将backoff2005里的训练数据转化为CRF++所需的训练数据格式，还是以微软亚洲研究院提供的中文分词语料为例，依然采用4- tag(B(Begin，词首), E(End，词尾), M(Middle，词中),  S(Single,单字词))标记集，只处理utf-8编码文本。原始训练集./icwb2-data/training /msr_training.utf8的形式是人工分好词的中文句子形式，如：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">"  &nbsp;人们 &nbsp;常 &nbsp;说 &nbsp;生活 &nbsp;是 &nbsp;一 &nbsp;部 &nbsp;教科书 &nbsp;， &nbsp;而 &nbsp;血 &nbsp;与 &nbsp;火 &nbsp;的 &nbsp;战争 &nbsp;&gt; &nbsp; &nbsp; &nbsp;更 &nbsp;是 &nbsp;不可多得  &nbsp;的 &nbsp;教科书 &nbsp;， &nbsp;她 &nbsp;确实 &nbsp;是 &nbsp;名副其实 &nbsp;的 &nbsp;' &nbsp;我 &nbsp;的 &nbsp;&gt; &nbsp; &nbsp; &nbsp;大学 &nbsp;' &nbsp;。<br />" &nbsp;心 &nbsp;静 &nbsp;渐 &nbsp;知 &nbsp;春 &nbsp;似 &nbsp;海 &nbsp;， &nbsp;花 &nbsp;深 &nbsp;每 &nbsp;觉 &nbsp;影 &nbsp;生 &nbsp;香 &nbsp;。<br />" &nbsp;吃 &nbsp;屎 &nbsp;的 &nbsp;东西 &nbsp;， &nbsp;连 &nbsp;一 &nbsp;捆 &nbsp;麦 &nbsp;也 &nbsp;铡 &nbsp;不 &nbsp;动 &nbsp;呀 &nbsp;？<br />他  &nbsp;" &nbsp;严格要求 &nbsp;自己 &nbsp;， &nbsp;从 &nbsp;一个 &nbsp;科举 &nbsp;出身 &nbsp;的 &nbsp;进士 &nbsp;成为 &nbsp;一个 &nbsp;伟&gt; &nbsp; &nbsp; &nbsp;大 &nbsp;的 &nbsp;民主主义 &nbsp;者  &nbsp;， &nbsp;进而 &nbsp;成为 &nbsp;一 &nbsp;位 &nbsp;杰出 &nbsp;的 &nbsp;党外 &nbsp;共产主义 &nbsp;战 士 &nbsp;， &nbsp;献身 &nbsp;于 &nbsp;崇高 &nbsp;的 &nbsp;共产主义 &nbsp;事业 &nbsp;。<br />" &nbsp;征 &nbsp;而 &nbsp;未 &nbsp;用 &nbsp;的 &nbsp;耕地 &nbsp;和 &nbsp;有 &nbsp;收益 &nbsp;的 &nbsp;土地 &nbsp;， &nbsp;不准 &nbsp;荒芜 &nbsp;。<br />" &nbsp;这 &nbsp;首先 &nbsp;是 &nbsp;个 &nbsp;民族 &nbsp;问题 &nbsp;， &nbsp;民族 &nbsp;的 &nbsp;感情 &nbsp;问题 &nbsp;。<br />' &nbsp;我 &nbsp;扔 &nbsp;了 &nbsp;两颗 &nbsp;手榴弹 &nbsp;， &nbsp;他 &nbsp;一下子 &nbsp;出 &nbsp;溜 &nbsp;下去 &nbsp;。<br />" &nbsp;废除 &nbsp;先前 &nbsp;存在 &nbsp;的 &nbsp;所有制 &nbsp;关系 &nbsp;， &nbsp;并不是 &nbsp;共产主义 &nbsp;所 &nbsp;独具 &nbsp;的 &nbsp; &nbsp; &nbsp; &nbsp;特征 &nbsp;。<br />" &nbsp;这个 &nbsp;案子 &nbsp;从 &nbsp;始 &nbsp;至今 &nbsp;我们 &nbsp;都 &nbsp;没有 &nbsp;跟 &nbsp;法官 &nbsp;接触 &nbsp;过 &nbsp;， &nbsp;也 &nbsp;&gt; &nbsp; &nbsp; &nbsp;没有 &nbsp;跟 &nbsp;原告 &nbsp;、 &nbsp;被告 &nbsp;接触 &nbsp;过 &nbsp;。<br />" &nbsp;你 &nbsp;只有 &nbsp;把 &nbsp;事情 &nbsp;做好 &nbsp;， &nbsp;大伙 &nbsp;才 &nbsp;服 &nbsp;你 &nbsp;。</div></td></tr></tbody></table></div>这里同样提供一个脚本 <a href="https://github.com/panyang/yuzhen_nlp_edu_tools/blob/master/CLPT/WordSegmentation/CRFSegment/make_crf_train_data.py" target="_blank">make_crf_train_data.py</a>，将这个训练语料转换为CRF++训练用的语料格式(2列，4-tag)：<br /><div style="border: 1px solid #9f9f9f; min-height: 450px; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11<br />12<br />13<br />14<br />15<br />16<br />17<br />18<br />19<br />20<br />21<br />22<br />23<br />24<br />25<br />26<br />27<br />28<br />29<br />30<br />31<br />32<br />33<br />34</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">#!/usr/bin/env python<br /># -*- coding: utf-8 -*-<br /># Author: <a href="mailto:52nlpcn@gmail.com" target="_blank">52nlpcn@gmail.com</a><br /># Copyright 2014 @ YuZhen Technology<br />#<br /># 4 tags for character tagging: B(Begin), E(End), M(Middle), S(Single)<br /><br />import codecs<br />import sys<br /><br />def character_tagging(input_file, output_file):<br />&nbsp; &nbsp; input_data = codecs.open(input_file, 'r', 'utf-8')<br />&nbsp; &nbsp; output_data = codecs.open(output_file, 'w', 'utf-8')<br />&nbsp; &nbsp; for line in input_data.readlines():<br />&nbsp; &nbsp; &nbsp; &nbsp; word_list = line.strip().split()<br />&nbsp; &nbsp; &nbsp; &nbsp; for word in word_list:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if len(word) == 1:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(word + "\tS\n")<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(word[0] + "\tB\n")<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for w in word[1:len(word)-1]:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(w + "\tM\n")<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(word[len(word)-1] + "\tE\n")<br />&nbsp; &nbsp; &nbsp; &nbsp; output_data.write("\n")<br />&nbsp; &nbsp; input_data.close()<br />&nbsp; &nbsp; output_data.close()<br /><br />if __name__ == '__main__':<br />&nbsp; &nbsp; if len(sys.argv) != 3:<br />&nbsp; &nbsp; &nbsp; &nbsp; print "pls use: python make_crf_train_data.py input output"<br />&nbsp; &nbsp; &nbsp; &nbsp; sys.exit()<br />&nbsp; &nbsp; input_file = sys.argv[1]<br />&nbsp; &nbsp; output_file = sys.argv[2]<br />&nbsp; &nbsp; character_tagging(input_file, output_file)</div></td></tr></tbody></table></div>只 需要执行"python make_crf_train_data.py  ./icwb2-data/training/msr_training.utf8 msr_training.tagging4crf.utf8"  即可得到CRF++要求的格式的训练文件msr_training.tagging4crf.utf8，样例如下：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">" S<br />人 B<br />们 E<br />常 S<br />说 S<br />生 B<br />活 E<br />是 S &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />一 S<br />部 S<br />..</div></td></tr></tbody></table></div>有了这份训练语料，就可以利用crf的训练工具crf_learn来训练模型了，执行如下命令即可：<br />crf_learn -f 3 -c 4.0 template msr_training.tagging4crf.utf8 crf_model<br />这 次训练的时间稍微有些长，在我的4G内存的mac  pro上跑了将近700轮，大约2个小时，最终训练的crf_model约51M。有了模型，现在我们需要做得还是准备一份CRF++用的测试语料，然后 利用CRF++的测试工具crf_test进行字标注。原始的测试语料是icwb2-data/testing/msr_test.utf8  ，样例如下：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">扬帆远东做与中国合作的先行<br />希腊的经济结构较特殊。<br />海运业雄踞全球之首，按吨位计占世界总数的１７％。<br />另外旅游、侨汇也是经济收入的重要组成部分，制造业规模相对较小。<br />多年来，中希贸易始终处于较低的水平，希腊几乎没有在中国投资。<br />十几年来，改革开放的中国经济高速发展，远东在崛起。<br />瓦西里斯的船只中有４０％驶向远东，每个月几乎都有两三条船停靠中国港口。<br />他感受到了中国经济发展的大潮。<br />他要与中国人合作。<br />他来到中国，成为第一个访华的大船主。</div></td></tr></tbody></table></div>这里我们同样提供一个python脚本 <a href="https://github.com/panyang/yuzhen_nlp_edu_tools/blob/master/CLPT/WordSegmentation/CRFSegment/make_crf_test_data.py" target="_blank">make_crf_test_data.py</a> 对测试语料进行处理，将其转换为CRF++要求的格式（2列，B作为最后一列的占位符)<br /><div style="border: 1px solid #9f9f9f; min-height: 450px; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11<br />12<br />13<br />14<br />15<br />16<br />17<br />18<br />19<br />20<br />21<br />22<br />23<br />24<br />25<br />26<br />27<br />28<br />29</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">#!/usr/bin/env python<br /># -*- coding: utf-8 -*-<br /># Author: <a href="mailto:52nlpcn@gmail.com" target="_blank">52nlpcn@gmail.com</a><br /># Copyright 2014 @ YuZhen Technology<br />#<br /># 4 tags for character tagging: B(Begin), E(End), M(Middle), S(Single)<br /><br />import codecs<br />import sys<br /><br />def character_split(input_file, output_file):<br />&nbsp; &nbsp; input_data = codecs.open(input_file, 'r', 'utf-8')<br />&nbsp; &nbsp; output_data = codecs.open(output_file, 'w', 'utf-8')<br />&nbsp; &nbsp; for line in input_data.readlines():<br />&nbsp; &nbsp; &nbsp; &nbsp; for word in line.strip():<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; word = word.strip()<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if word:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(word + "\tB\n")<br />&nbsp; &nbsp; &nbsp; &nbsp; output_data.write("\n")<br />&nbsp; &nbsp; input_data.close()<br />&nbsp; &nbsp; output_data.close()<br /><br />if __name__ == '__main__':<br />&nbsp; &nbsp; if len(sys.argv) != 3:<br />&nbsp; &nbsp; &nbsp; &nbsp; print "pls use: python make_crf_test_data.py input output"<br />&nbsp; &nbsp; &nbsp; &nbsp; sys.exit()<br />&nbsp; &nbsp; input_file = sys.argv[1]<br />&nbsp; &nbsp; output_file = sys.argv[2]<br />&nbsp; &nbsp; character_split(input_file, output_file)</div></td></tr></tbody></table></div>执行"python make_crf_test_data.py ./icwb2-data/testing/msr_test.utf8 msr_test4crf.utf8"即可得到可用于CRF++测试的测试语料msr_test4crf.utf8，样例如下：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">扬 B<br />帆 B<br />远 B<br />东 B<br />做 B<br />与 B<br />中 B<br />国 B<br />合 B<br />作 B &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />..</div></td></tr></tbody></table></div>现在执行crf_test即可得到字标注结果：<br />crf_test -m crf_model msr_test4crf.utf8 &gt; msr_test4crf.tag.utf8<br />msr_test4crf.tag.utf8即是标注结果，样例如下：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">扬 B &nbsp; B<br />帆 B &nbsp; E<br />远 B &nbsp; B<br />东 B &nbsp; E<br />做 B &nbsp; S<br />与 B &nbsp; S<br />中 B &nbsp; B<br />国 B &nbsp; E<br />合 B &nbsp; B<br />作 B &nbsp; E &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <br />..</div></td></tr></tbody></table></div>最后我们还需要一个脚本，按标注的词位信息讲这份结果再转化为分词结果，这里我们仍然提供一个转换脚本 <a href="https://github.com/panyang/yuzhen_nlp_edu_tools/blob/master/CLPT/WordSegmentation/CRFSegment/crf_data_2_word.py" target="_blank">crf_data_2_word.py</a> :<br /><div style="border: 1px solid #9f9f9f; min-height: 450px; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11<br />12<br />13<br />14<br />15<br />16<br />17<br />18<br />19<br />20<br />21<br />22<br />23<br />24<br />25<br />26<br />27<br />28<br />29<br />30<br />31<br />32<br />33<br />34<br />35<br />36<br />37<br />38</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">#!/usr/bin/env python<br /># -*- coding: utf-8 -*-<br /># Author: <a href="mailto:52nlpcn@gmail.com" target="_blank">52nlpcn@gmail.com</a><br /># Copyright 2014 @ YuZhen Technology<br />#<br /># 4 tags for character tagging: B(Begin), E(End), M(Middle), S(Single)<br /><br />import codecs<br />import sys<br /><br />def character_2_word(input_file, output_file):<br />&nbsp; &nbsp; input_data = codecs.open(input_file, 'r', 'utf-8')<br />&nbsp; &nbsp; output_data = codecs.open(output_file, 'w', 'utf-8')<br />&nbsp; &nbsp; for line in input_data.readlines():<br />&nbsp; &nbsp; &nbsp; &nbsp; if line == "\n":<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write("\n")<br />&nbsp; &nbsp; &nbsp; &nbsp; else:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; char_tag_pair = line.strip().split('\t')<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; char = char_tag_pair[0]<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tag = char_tag_pair[2]<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if tag == 'B':<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(' ' + char)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif tag == 'M':<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(char)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif tag == 'E':<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(char + ' ')<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else: # tag == 'S'<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(' ' + char + ' ')<br />&nbsp; &nbsp; input_data.close()<br />&nbsp; &nbsp; output_data.close()<br /><br />if __name__ == '__main__':<br />&nbsp; &nbsp; if len(sys.argv) != 3:<br />&nbsp; &nbsp; &nbsp; &nbsp; print "pls use: python crf_data_2_word.py input output"<br />&nbsp; &nbsp; &nbsp; &nbsp; sys.exit()<br />&nbsp; &nbsp; input_file = sys.argv[1]<br />&nbsp; &nbsp; output_file = sys.argv[2]<br />&nbsp; &nbsp; character_2_word(input_file, output_file)</div></td></tr></tbody></table></div>只需执行"python crf_data_2_word.py msr_test4crf.tag.utf8 msr_test4crf.tag2word.utf8" 即可得到合并后的分词结果文件 msr_test4crf.tag2word.utf8，样例如下：<br /><div style="border: 1px solid #9f9f9f; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">&nbsp;扬帆 &nbsp;远东 &nbsp;做 &nbsp;与 &nbsp;中国 &nbsp;合作 &nbsp;的 &nbsp;先行 <br />&nbsp;希腊 &nbsp;的 &nbsp;经济 &nbsp;结构 &nbsp;较 &nbsp;特殊 &nbsp;。 <br />&nbsp;海运 &nbsp;业 &nbsp;雄踞 &nbsp;全球 &nbsp;之 &nbsp;首 &nbsp;， &nbsp;按 &nbsp;吨 &nbsp;位 &nbsp;计 &nbsp;占 &nbsp;世界 &nbsp;总数 &nbsp;的 &nbsp;１７％ &nbsp;。 <br />&nbsp;另外 &nbsp;旅游 &nbsp;、 &nbsp;侨汇 &nbsp;也是 &nbsp;经济 &nbsp;收入 &nbsp;的 &nbsp;重要 &nbsp;组成部分 &nbsp;， &nbsp;制造业 &nbsp;规模 &nbsp;相对 &nbsp;较小 &nbsp;。 <br />&nbsp;多年来 &nbsp;， &nbsp;中 &nbsp;希 &nbsp;贸易 &nbsp;始终 &nbsp;处于 &nbsp;较低 &nbsp;的 &nbsp;水平 &nbsp;， &nbsp;希腊 &nbsp;几乎 &nbsp;没有 &nbsp;在 &nbsp;中国 &nbsp;投资 &nbsp;。 <br />&nbsp;十几年 &nbsp;来 &nbsp;， &nbsp;改革开放 &nbsp;的 &nbsp;中国 &nbsp;经济 &nbsp;高速 &nbsp;发展 &nbsp;， &nbsp;远东 &nbsp;在 &nbsp;崛起 &nbsp;。 <br />&nbsp;瓦西里斯 &nbsp;的 &nbsp;船只 &nbsp;中 &nbsp;有 &nbsp;４０％ &nbsp;驶 &nbsp;向 &nbsp;远东 &nbsp;， &nbsp;每个 &nbsp;月 &nbsp;几乎 &nbsp;都 &nbsp;有 &nbsp;两三条 &nbsp;船 &nbsp;停靠 &nbsp;中国 &nbsp;港口 &nbsp;。 <br />&nbsp;他 &nbsp;感受 &nbsp;到 &nbsp;了 &nbsp;中国 &nbsp;经济 &nbsp;发展 &nbsp;的 &nbsp;大潮 &nbsp;。 <br />&nbsp;他 &nbsp;要 &nbsp;与 &nbsp;中国人 &nbsp;合作 &nbsp;。 <br />&nbsp;他 &nbsp;来到 &nbsp;中国 &nbsp;， &nbsp;成为 &nbsp;第一个 &nbsp;访 &nbsp;华 &nbsp;的 &nbsp;大船 &nbsp;主 &nbsp;。<br />&nbsp;...</div></td></tr></tbody></table></div>有了这个CRF字标注分词结果，我们就可以利用backoff2005的测试脚本来测一下这次分词的效果了：<br />./icwb2-data/scripts/score  ./icwb2-data/gold/msr_training_words.utf8  ./icwb2-data/gold/msr_test_gold.utf8 msr_test4crf.tag2word.utf8 &gt;  msr_crf_segment.score<br />结果如下：<br />=== SUMMARY:<br />=== TOTAL INSERTIONS:   1412<br />=== TOTAL DELETIONS:    1305<br />=== TOTAL SUBSTITUTIONS:        2449<br />=== TOTAL NCHANGE:      5166<br />=== TOTAL TRUE WORD COUNT:      106873<br />=== TOTAL TEST WORD COUNT:      106980<br />=== TOTAL TRUE WORDS RECALL:    0.965<br />=== TOTAL TEST WORDS PRECISION: 0.964<br />=== F MEASURE:  0.964<br />=== OOV Rate:   0.026<br />=== OOV Recall Rate:    0.647<br />=== IV Recall Rate:     0.974<br />###     msr_test4crf.tag2word.utf8      1412    1305    2449    5166     106873  106980  0.965   0.964   0.964   0.026   0.647   0.974<br />这次我们获得了一个准确率，召回率以及F值都在96%以上的结果，相对于前面几节的测试结果，这个CRF字标注分词结果还相对不错。不过是不是感觉上面的步骤有些繁琐，有没有一次到位的CRF分词器，这里我们同样提供一个CRF分词脚本 <a href="https://github.com/panyang/yuzhen_nlp_edu_tools/blob/master/CLPT/WordSegmentation/CRFSegment/crf_segmenter.py" target="_blank">crf_segmenter.py</a> ，利用CRF++的python工具包，做到一次输入，一次输出：<br /><div style="border: 1px solid #9f9f9f; min-height: 450px; overflow: auto; white-space: nowrap; width: 620px;"><table cellpadding="0" cellspacing="0"><tbody><tr><td style="background-color: #eeeeee; border-right: 1px solid #9f9f9f; color: #888888; font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; text-align: center;"><div>1<br />2<br />3<br />4<br />5<br />6<br />7<br />8<br />9<br />10<br />11<br />12<br />13<br />14<br />15<br />16<br />17<br />18<br />19<br />20<br />21<br />22<br />23<br />24<br />25<br />26<br />27<br />28<br />29<br />30<br />31<br />32<br />33<br />34<br />35<br />36<br />37<br />38<br />39<br />40<br />41<br />42<br />43<br />44<br />45<br />46<br />47<br />48<br />49<br />50</div></td><td><div style="font: normal 12px/1.4em Monaco,Lucida Console,monospace; padding: 5px; white-space: nowrap;">#!/usr/bin/env python<br /># -*- coding: utf-8 -*-<br /># Author: <a href="mailto:52nlpcn@gmail.com" target="_blank">52nlpcn@gmail.com</a><br /># Copyright 2014 @ YuZhen Technology<br />#<br /># CRF Segmenter based character tagging:<br /># &nbsp; &nbsp; 4 tags for character tagging: B(Begin), E(End), M(Middle), S(Single)<br /><br />import codecs<br />import sys<br /><br />import CRFPP<br /><br />def crf_segmenter(input_file, output_file, tagger):<br />&nbsp; &nbsp; input_data = codecs.open(input_file, 'r', 'utf-8')<br />&nbsp; &nbsp; output_data = codecs.open(output_file, 'w', 'utf-8')<br />&nbsp; &nbsp; for line in input_data.readlines():<br />&nbsp; &nbsp; &nbsp; &nbsp; tagger.clear()<br />&nbsp; &nbsp; &nbsp; &nbsp; for word in line.strip():<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; word = word.strip()<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if word:<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tagger.add((word + "\to\tB").encode('utf-8'))<br />&nbsp; &nbsp; &nbsp; &nbsp; tagger.parse()<br />&nbsp; &nbsp; &nbsp; &nbsp; size = tagger.size()<br />&nbsp; &nbsp; &nbsp; &nbsp; xsize = tagger.xsize()<br />&nbsp; &nbsp; &nbsp; &nbsp; for i in range(0, size):<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for j in range(0, xsize):<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; char = tagger.x(i, j).decode('utf-8')<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; tag = tagger.y2(i)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if tag == 'B':<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(' ' + char)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif tag == 'M':<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(char)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif tag == 'E':<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(char + ' ')<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else: # tag == 'S'<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output_data.write(' ' + char + ' ')<br />&nbsp; &nbsp; &nbsp; &nbsp; output_data.write('\n')<br />&nbsp; &nbsp; input_data.close()<br />&nbsp; &nbsp; output_data.close()<br /><br />if __name__ == '__main__':<br />&nbsp; &nbsp; if len(sys.argv) != 4:<br />&nbsp; &nbsp; &nbsp; &nbsp; print "pls use: python crf_segmenter.py model input output"<br />&nbsp; &nbsp; &nbsp; &nbsp; sys.exit()<br />&nbsp; &nbsp; crf_model = sys.argv[1]<br />&nbsp; &nbsp; input_file = sys.argv[2]<br />&nbsp; &nbsp; output_file = sys.argv[3]<br />&nbsp; &nbsp; tagger = CRFPP.Tagger("-m " + crf_model)<br />&nbsp; &nbsp; crf_segmenter(input_file, output_file, tagger)</div></td></tr></tbody></table></div>只 需执行"python crf_segmenter.py crf_model ./icwb2-data/testing/msr_test.utf8  msr_test.seg.utf8"即可得到与前面几步得到的分词结果完全一致的CRF分词结果：msr_test.seg.utf8 。<br />好了，到此为止，关于字标注中文分词的系列终于可以画上句号了，这个系列中所举的例子以及所提供的脚本都是toy级别的中文分词工具，距离一个真正实用的中文分词器还有很多路要走，不过既然路已经打开，欢迎大家和我们一起继续探索中文分词的奥秘。<br />最后再打个广告：今天是2013年的最后一天，这一年，我们创业了，成立了一家公司"<a href="http://www.yuzhenkeji.com/" target="_blank">语真科技</a>"，2014年，我们除了关注在线教育外，也致力于<a href="http://www.yuzhenkeji.com/nlpservice" target="_blank">NLP技术的普及，推广和应用</a>，如果您有相关的需求，欢迎和我们联系，微博 @52nlp 或者邮件联系 <a href="mailto:support@yuzhenkeji.com" target="_blank">support@yuzhenkeji.com</a> 都可以，最后祝大家新年顺心如意！<br />注：原创文章，转载请注明出处"<a href="http://www.52nlp.cn/" target="_blank">我爱自然语言处理</a>"：<a href="http://www.52nlp.cn/" target="_blank">www.52nlp.cn</a><br />本文链接地址：<a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%954" target="_blank">http://www.52nlp.cn/中文分词入门之字标注法4</a><br /><div>相关文章:<br /><ol><li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%953" rel="bookmark" target="_blank" title="中文分词入门之字标注法3">中文分词入门之字标注法3</a></li><li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%952" rel="bookmark" target="_blank" title="中文分词入门之字标注法2">中文分词入门之字标注法2</a></li><li><a href="http://www.52nlp.cn/maximum-matching-method-of-chinese-word-segmentation" rel="bookmark" target="_blank" title="中文分词入门之最大匹配法">中文分词入门之最大匹配法</a></li><li><a href="http://www.52nlp.cn/beautiful-data-%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%89%E5%88%86%E8%AF%8D3" rel="bookmark" target="_blank" title="Beautiful Data-统计语言模型的应用三：分词3">Beautiful Data-统计语言模型的应用三：分词3</a></li><li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E8%B5%84%E6%BA%90" rel="bookmark" target="_blank" title="中文分词入门之资源">中文分词入门之资源</a></li><li><a href="http://www.52nlp.cn/beautiful-data-%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%89%E5%88%86%E8%AF%8D7" rel="bookmark" target="_blank" title="Beautiful Data-统计语言模型的应用三：分词7">Beautiful Data-统计语言模型的应用三：分词7</a></li><li><a href="http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%951" rel="bookmark" target="_blank" title="中文分词入门之字标注法1">中文分词入门之字标注法1</a></li><li><a href="http://www.52nlp.cn/beautiful-data-%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%89%E5%88%86%E8%AF%8D6" rel="bookmark" target="_blank" title="Beautiful Data-统计语言模型的应用三：分词6">Beautiful Data-统计语言模型的应用三：分词6</a></li><li><a href="http://www.52nlp.cn/%E6%97%A5%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8-mecab-%E6%96%87%E6%A1%A3" rel="bookmark" target="_blank" title="日文分词器 Mecab 文档">日文分词器 Mecab 文档</a></li><li><a href="http://www.52nlp.cn/beautiful-data-%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%89%E5%88%86%E8%AF%8D8" rel="bookmark" target="_blank" title="Beautiful Data-统计语言模型的应用三：分词8">Beautiful Data-统计语言模型的应用三：分词8</a></li></ol></div></div></td></tr></tbody></table></div>