---
layout: post
title: "开源中国：Facebook 运维内幕曝光：一人管理2万台服务器"
date: '2013-11-25T14:20:00.002+08:00'
author: Wenh Q
tags: 
modified_time: '2013-11-25T14:20:48.614+08:00'
blogger_id: tag:blogger.com,1999:blog-4961947611491238191.post-5636723299898430988
blogger_orig_url: http://binaryware.blogspot.com/2013/11/facebook-2.html
---

<div style="margin: 10px; padding: 5px;"><div style="font-size: 18px;"><a href="http://www.oschina.net/news/46199/facebook-ops-staffer-manages-20000-servers">Facebook 运维内幕曝光：一人管理2万台服务器</a>     </div><div style="font-size: 13px;">Via <a href="http://www.oschina.net/?from=rss">开源中国社区最新新闻</a>     </div></div><div style="font-size: 13px; padding: 15px 0 10px 10px;">目前，Facebook 已经凭借它在网络基础建设上的可扩展能力成为了行业的领军者。Facebook 数据中心运维主管 Delfina Eberly（下图人物） 在"7x24 Exchange 2013 秋季会议"上的演讲中为我们透露了 Facebook 部分内部运维数据，下面我们来具体了解下。 <br /><div style="text-align: center;"><img alt="" src="http://static.oschina.net/uploads/img/201311/23085307_Mey8.jpg" /><br />Facebook 数据中心运维主管 Delfina Eberly  </div><br /><strong><span style="font-size: medium;"><span style="color: red;">服务器数量惊人，一人管理 2 万台</span></span></strong> <br /><br />Facebook 服务器数量惊人，其硬件方面的工作重点主要放在"可服务性"上，内容也涉及服务器的初期设计，一系列工作的目标就是为了保证数据机房的设备维修最简单、最 省时。她介绍说，每个 Facebook 数据中心的运维工作人员管理了至少 20,000 台服务器，其中部分员工会管理数量高达 26,000 多个的系统。 <br /><br />近期 Facebook 的服务器与管理人数比又创下了新高，目前已经超过 10000:1，可以查看文章<a href="http://highscalability.com/blog/2013/11/19/we-finally-cracked-the-10k-problem-this-time-for-managing-se.html" target="_blank">高扩展性</a>对此进行更加详细的了解。 <br /><br /><strong><span style="font-size: medium;"><span style="color: red;">大数据汹涌，运维工作不轻松</span></span></strong></div><br /><br />在 Facebook 数据中心做运维工作并不轻松，对工作人员的能力要求很高。他们每天面对的是海量数据。 <br /><br />据统计，Facebook 目前拥有 11.5 亿用户，日常登录用户约 7.2 亿。每天 Facebook 用户分享的内容达到 47.5 亿条，"赞"按钮点击次数近 45 亿次。Facebook 目前存储了 2400 亿张照片，每月照片存储容量约增加 7 PB（注，单位换算：1PB=1024TB）。 <br /><br /><strong><span style="color: red;"><span style="font-size: medium;">自动故障诊断系统：原为留住人才</span></span></strong> <br /><br />为了管理运维工作，Facebook 已经开发了相应软件来自动化处理日常运维任务，如 CYBORG 可自动检测服务器问题并进行修复。如果 CYBORG 无法自动修复检查出的问题，系统将自动给订单系统发送警告，并分派给数据中心工作人员，以对相应问题进行详细追踪与分析。 <br /><br />Eberly 提�   �，自动化工作的目标是尽量避免将技术人员派往现场解决问题，除非必须对服务器进行现场处理。强调自动化不是因为 Facebook 对打造无人数据中心感兴趣，原因在于 Facebook 重视自己的员工。 <br /><br />Eberly 解释说：我们要留住人才，因为大家更喜欢高水平的任务，公司希望让他们留下来与我们一起进步成长，这对 Facebook 来说至关重要。 <br /><br /><strong><span style="color: red;"><span style="font-size: medium;">"可服务性"主导服务器设计：节时 54%</span></span></strong> <br /><br />在 Facebook，运维团队的时间与工作量是根据 Facebook 硬件设计来安排的。比方说，全部服务器从头开始就坚持"可服务性"这一原则来进行设计，那么数据中心的工作人员就没有必要老钻机房了；服务器被设计成无需 工具就可以对磁盘和组件进行替换。这样做的结果就是：Facebook 用来修理服务   器的时间减少了 54%。 <br /><br />Eberly 介绍说，Facebook 运维团队会仔细跟踪设备故障率，这一数据会为公司的采购提供参考。公司的财产管理和订单系统用序列号来跟踪硬盘和其他组件，这方便完整了解每个硬件的生命周期。 <br /><br />Eberly 还提到，虽然这些系统很复杂，但并不需要太多开发者。Facebook 的运维团队仅有 3 名软件工程师，但他们对数据中心的工作来讲至关重要。 <br /><br /><strong><span style="color: red;"><span style="font-size: medium;">最后</span></span></strong> <br /><br />从 Eberly 的介绍中，我们可以看到 Facebook 在可扩展性网络建设上的实力。同时，这也为行业提供了一些可参考的经验，如：开发自动故障系统，根据"可服务性"设计基础架构。同时，运维也是一个系统工程，需要得到其他部门的配合支持才行。 <br /><br />Via <a href="http://www.datacenterknowledge.com/archi%20%20%20ves/2013/11/20/facebook-ops-staffer-manages-20000-servers/" target="_blank">Datacenterknowledge</a>